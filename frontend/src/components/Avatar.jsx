
/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.2.3 public/models/64f1a714fe61576b46f27ca2.glb -o src/components/Avatar.jsx -k -r public
*/

import { useAnimations, useGLTF } from "@react-three/drei";
import { useFrame } from "@react-three/fiber";
import { button, useControls } from "leva";
import React, { useEffect, useRef, useState } from "react";
import * as THREE from "three";
import { useChat } from "../hooks/useChat";

const facialExpressions = {
  default: {},
  smile: {
    browInnerUp: 0.17,
    eyeSquintLeft: 0.4,
    eyeSquintRight: 0.44,
    noseSneerLeft: 0.17,
    noseSneerRight: 0.14,
    mouthPressLeft: 0.61,
    mouthPressRight: 0.41,
  },
  // ... (your other expressions unchanged)
};

const corresponding = {
  A: "viseme_PP",
  B: "viseme_kk",
  C: "viseme_I",
  D: "viseme_AA",
  E: "viseme_O",
  F: "viseme_U",
  G: "viseme_FF",
  H: "viseme_TH",
  X: "viseme_PP",
};

let setupMode = false;

// Voice management
let voicesLoaded = false;
let availableVoices = [];
let selectedVoice = null;

const loadVoices = () => {
  return new Promise((resolve) => {
    if (voicesLoaded && availableVoices.length > 0) {
      resolve(availableVoices);
      return;
    }

    const voices = speechSynthesis.getVoices();
    if (voices.length > 0) {
      availableVoices = voices;
      voicesLoaded = true;
      resolve(voices);
    } else {
      const onVoicesChanged = () => {
        speechSynthesis.removeEventListener('voiceschanged', onVoicesChanged);
        availableVoices = speechSynthesis.getVoices();
        voicesLoaded = true;
        resolve(availableVoices);
      };
      speechSynthesis.addEventListener('voiceschanged', onVoicesChanged);
    }
  });
};

const getUKEnglishFemaleVoice = (voices) => {
  // If we already found a good UK voice, reuse it
  if (selectedVoice) {
    const stillAvailable = voices.find(v => v.name === selectedVoice.name);
    if (stillAvailable) return stillAvailable;
  }

  console.log("=== AVAILABLE VOICES ===");
  voices.forEach(voice => {
    console.log(`Voice: ${voice.name} | Lang: ${voice.lang} | Default: ${voice.default}`);
  });

  // STRICT UK ENGLISH FEMALE VOICE SELECTION
  const ukFemaleVoicesPriority = [
    // Perfect UK English Female Voices (in priority order)
    "Google UK English Female",
    "Microsoft Hazel Desktop",
    "Hazel",
    "English (UK) Female",
    "English UK Female",
    "en-GB Female",
    "GB Female",
    
    // UK English voices (might be female)
    "Google UK English",
    "English (UK)",
    "en-GB",
    "United Kingdom",
    
    // Fallback: Any female English voice with UK accent hints
    "English Female",
    "Female"
  ];

  // PRIORITY 1: Exact UK English female voice match
  for (const voiceName of ukFemaleVoicesPriority) {
    const voice = voices.find(v => 
      v.name.toLowerCase() === voiceName.toLowerCase() ||
      v.name.includes(voiceName) ||
      v.name.toLowerCase().includes(voiceName.toLowerCase())
    );
    
    if (voice) {
      // Verify it's UK English
      const isUKEnglish = 
        voice.lang.includes('GB') || 
        voice.lang.includes('en-GB') ||
        voice.lang.includes('UK') ||
        voice.name.includes('UK') ||
        voice.name.includes('GB') ||
        voice.name.includes('Hazel') || // Windows UK female
        voice.name.includes('Google UK'); // Chrome UK voices
      
      if (isUKEnglish) {
        selectedVoice = voice;
        console.log("ðŸŽ¯ SELECTED PERFECT UK FEMALE VOICE:", voice.name);
        return voice;
      }
    }
  }

  // PRIORITY 2: UK English voices (any gender, but prefer female)
  const ukEnglishVoices = voices.filter(voice => 
    voice.lang.includes('GB') || 
    voice.lang.includes('en-GB') ||
    voice.lang.includes('UK') ||
    voice.name.includes('UK') ||
    voice.name.includes('GB') ||
    voice.name.includes('Hazel') ||
    voice.name.includes('Google UK')
  );

  if (ukEnglishVoices.length > 0) {
    // Prefer female UK voices
    const femaleUKVoice = ukEnglishVoices.find(voice => 
      voice.name.includes('Female') ||
      voice.name.includes('female') ||
      voice.name.includes('Hazel') ||
      !voice.name.includes('Male')
    ) || ukEnglishVoices[0];
    
    selectedVoice = femaleUKVoice;
    console.log("SELECTED UK ENGLISH VOICE:", selectedVoice.name);
    return selectedVoice;
  }

  // PRIORITY 3: Any English female voice with British/UK hints
  const englishFemaleVoices = voices.filter(voice => {
    const isEnglish = voice.lang.startsWith('en');
    const isFemale = 
      voice.name.includes("Female") ||
      voice.name.includes("female") ||
      voice.name.includes("Hazel") ||
      (!voice.name.includes("Male") && !voice.name.includes("David"));
    
    const hasUKHint = 
      voice.name.includes("UK") ||
      voice.name.includes("GB") ||
      voice.name.includes("British") ||
      voice.name.includes("Hazel");
    
    return isEnglish && isFemale && hasUKHint;
  });

  if (englishFemaleVoices.length > 0) {
    selectedVoice = englishFemaleVoices[0];
    console.log("SELECTED ENGLISH FEMALE VOICE WITH UK HINTS:", selectedVoice.name);
    return selectedVoice;
  }

  // PRIORITY 4: Default UK English voice
  const defaultUKVoice = voices.find(voice => 
    (voice.lang.includes('GB') || voice.lang.includes('en-GB')) && 
    voice.default
  );

  if (defaultUKVoice) {
    selectedVoice = defaultUKVoice;
    console.log("SELECTED DEFAULT UK VOICE:", selectedVoice.name);
    return selectedVoice;
  }

  // PRIORITY 5: Any female English voice
  const anyFemaleEnglish = voices.find(voice => 
    voice.lang.startsWith('en') &&
    (voice.name.includes("Female") ||
     voice.name.includes("female") ||
     !voice.name.includes("Male"))
  );

  if (anyFemaleEnglish) {
    selectedVoice = anyFemaleEnglish;
    console.log("SELECTED ANY FEMALE ENGLISH VOICE:", selectedVoice.name);
    return selectedVoice;
  }

  // LAST RESORT: First UK English voice or first English voice
  const firstUKVoice = voices.find(voice => 
    voice.lang.includes('GB') || voice.lang.includes('en-GB')
  ) || voices.find(voice => voice.lang.startsWith('en'));

  if (firstUKVoice) {
    selectedVoice = firstUKVoice;
    console.log("SELECTED FIRST AVAILABLE ENGLISH VOICE:", selectedVoice.name);
    return firstUKVoice;
  }

  console.warn("No suitable voice found, using default");
  selectedVoice = voices.find(voice => voice.default) || voices[0];
  return selectedVoice;
};

export function Avatar(props) {
  const group = useRef();

  // Load model + animations
  const { nodes, materials, scene } = useGLTF("/models/68d616575327e5b9d7ee6f07.glb");
  const { animations } = useGLTF("/models/animations.glb");
  const { actions, mixer } = useAnimations(animations, group);

  const { message, onMessagePlayed, chat } = useChat();
  const [animation, setAnimation] = useState("Idle");
  const [lipsync, setLipsync] = useState();
  const [facialExpression, setFacialExpression] = useState("");
  const [blink, setBlink] = useState(false);
  const [winkLeft, setWinkLeft] = useState(false);
  const [winkRight, setWinkRight] = useState(false);
  const [audio, setAudio] = useState();
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [fakeLipSyncValue, setFakeLipSyncValue] = useState(0);

  // Pre-load voices on component mount
  useEffect(() => {
    loadVoices().then(voices => {
      console.log("Pre-loaded voices count:", voices.length);
      const ukVoice = getUKEnglishFemaleVoice(voices);
      console.log("ðŸŽ¯ Pre-selected UK Female voice:", ukVoice?.name);
    });
  }, []);

  // Improve GLB clarity
  useEffect(() => {
    scene.traverse((child) => {
      if (child.isMesh && child.material) {
        const mats = Array.isArray(child.material) ? child.material : [child.material];
        mats.forEach((mat) => {
          if (mat.map) {
            mat.map.anisotropy = 16;
            mat.map.minFilter = THREE.LinearFilter;
            mat.map.magFilter = THREE.LinearFilter;
            mat.map.needsUpdate = true;
          }
          if (mat.normalMap) {
            mat.normalMap.anisotropy = 16;
            mat.normalMap.needsUpdate = true;
          }
        });
      }
    });
  }, [scene]);

  // Animation handling
  useEffect(() => {
    if (!animations || animations.length === 0) return;
    if (!actions || !actions[animation]) return;

    const action = actions[animation];
    action.reset().fadeIn(0.5).play();

    return () => {
      if (actions[animation]) actions[animation].fadeOut(0.5);
    };
  }, [animation, actions]);

  // Handle message-driven animation + facial expressions
  useEffect(() => {
    if (!message) {
      setAnimation("Idle");
      setIsSpeaking(false);
      setFakeLipSyncValue(0);
      return;
    }

    setAnimation(message.animation || "Idle");
    setFacialExpression(message.facialExpression || "");
    setLipsync(message.lipsync);
    setIsSpeaking(true);

    // Browser TTS with UK English female voice
    if ("speechSynthesis" in window) {
      // Cancel any ongoing speech immediately
      speechSynthesis.cancel();

      // Use setTimeout to ensure cancellation is processed
      setTimeout(() => {
        loadVoices().then(voices => {
          const utterance = new SpeechSynthesisUtterance(message.text);
          utterance.rate = 0.9; // Slightly slower for clear British English
          utterance.pitch = 1.0; // Neutral pitch for natural British sound
          utterance.volume = 1.0;
          
          // Force UK English language
          utterance.lang = 'en-GB';

          const ukVoice = getUKEnglishFemaleVoice(voices);
          if (ukVoice) {
            utterance.voice = ukVoice;
            console.log("ðŸŽ¯ SPEAKING WITH UK FEMALE VOICE:", ukVoice.name, "| Language:", ukVoice.lang);
          }

          utterance.onend = () => {
            console.log("Speech ended");
            setIsSpeaking(false);
            setFakeLipSyncValue(0);
            onMessagePlayed();
          };
          
          utterance.onerror = (error) => {
            console.error("Speech synthesis error:", error);
            setIsSpeaking(false);
            setFakeLipSyncValue(0);
            onMessagePlayed();
          };

          utterance.onstart = () => {
            console.log("ðŸŽ¤ Speech started with UK female voice");
            setIsSpeaking(true);
          };

          // Small delay to ensure clean speech start
          setTimeout(() => {
            speechSynthesis.speak(utterance);
          }, 50);
        });
      }, 100);
    } else {
      setIsSpeaking(true);
      setTimeout(() => {
        setIsSpeaking(false);
        setFakeLipSyncValue(0);
        onMessagePlayed();
      }, message.text.length * 120);
    }
  }, [message, onMessagePlayed]);

  // Fake lip sync animation
  useEffect(() => {
    if (!isSpeaking) {
      setFakeLipSyncValue(0);
      return;
    }

    let animationFrameId;
    let startTime = Date.now();
    let lastUpdate = 0;

    const animateLipSync = () => {
      const currentTime = Date.now();
      const elapsed = currentTime - startTime;
      
      // Update lip sync value every 100ms for smooth animation
      if (currentTime - lastUpdate > 100) {
        // Create a random but smooth lip movement pattern
        const timeFactor = elapsed * 0.01;
        const lipValue = Math.abs(Math.sin(timeFactor) * 0.8 + Math.random() * 0.2);
        setFakeLipSyncValue(Math.min(lipValue, 1));
        lastUpdate = currentTime;
      }

      if (isSpeaking) {
        animationFrameId = requestAnimationFrame(animateLipSync);
      }
    };

    animateLipSync();

    return () => {
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    };
  }, [isSpeaking]);

  // Morph targets
  const lerpMorphTarget = (target, value, speed = 0.1) => {
    scene.traverse((child) => {
      if (child.isSkinnedMesh && child.morphTargetDictionary) {
        const index = child.morphTargetDictionary[target];
        if (index !== undefined && child.morphTargetInfluences[index] !== undefined) {
          child.morphTargetInfluences[index] = THREE.MathUtils.lerp(
            child.morphTargetInfluences[index],
            value,
            speed
          );
        }
      }
    });
  };

  useFrame(() => {
    Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
      const mapping = facialExpressions[facialExpression];
      if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") return;
      if (mapping && mapping[key]) {
        lerpMorphTarget(key, mapping[key], 0.1);
      } else {
        lerpMorphTarget(key, 0, 0.1);
      }
    });

    lerpMorphTarget("eyeBlinkLeft", blink || winkLeft ? 1 : 0, 0.5);
    lerpMorphTarget("eyeBlinkRight", blink || winkRight ? 1 : 0, 0.5);

    if (setupMode) return;

    // Apply fake lip sync when speaking
    if (isSpeaking) {
      // Use multiple viseme targets for more natural fake lip movement
      const visemeTargets = ["viseme_AA", "viseme_O", "viseme_U", "viseme_I", "viseme_PP"];
      const activeTarget = visemeTargets[Math.floor((Date.now() / 200) % visemeTargets.length)];
      
      visemeTargets.forEach(target => {
        if (target === activeTarget) {
          lerpMorphTarget(target, fakeLipSyncValue, 0.3);
        } else {
          lerpMorphTarget(target, 0, 0.2);
        }
      });
    } else {
      // Reset all viseme targets when not speaking
      Object.values(corresponding).forEach((value) => {
        lerpMorphTarget(value, 0, 0.1);
      });
    }

    const appliedMorphTargets = [];
    if (message && lipsync && audio) {
      const currentAudioTime = audio.currentTime;
      for (let i = 0; i < lipsync.mouthCues.length; i++) {
        const mouthCue = lipsync.mouthCues[i];
        if (currentAudioTime >= mouthCue.start && currentAudioTime <= mouthCue.end) {
          appliedMorphTargets.push(corresponding[mouthCue.value]);
          lerpMorphTarget(corresponding[mouthCue.value], 1, 0.2);
          break;
        }
      }
    }

    Object.values(corresponding).forEach((value) => {
      if (!appliedMorphTargets.includes(value)) lerpMorphTarget(value, 0, 0.1);
    });
  });

  // Blink cycle
  useEffect(() => {
    let blinkTimeout;
    const nextBlink = () => {
      blinkTimeout = setTimeout(() => {
        setBlink(true);
        setTimeout(() => {
          setBlink(false);
          nextBlink();
        }, 200);
      }, THREE.MathUtils.randInt(1000, 5000));
    };
    nextBlink();
    return () => clearTimeout(blinkTimeout);
  }, []);

  return (
    <group {...props} dispose={null} ref={group}>
      <primitive object={nodes.Hips} />
      <skinnedMesh name="Wolf3D_Body" geometry={nodes.Wolf3D_Body.geometry} material={materials.Wolf3D_Body} skeleton={nodes.Wolf3D_Body.skeleton} />
      <skinnedMesh name="Wolf3D_Outfit_Bottom" geometry={nodes.Wolf3D_Outfit_Bottom.geometry} material={materials.Wolf3D_Outfit_Bottom} skeleton={nodes.Wolf3D_Outfit_Bottom.skeleton} />
      <skinnedMesh name="Wolf3D_Outfit_Footwear" geometry={nodes.Wolf3D_Outfit_Footwear.geometry} material={materials.Wolf3D_Outfit_Footwear} skeleton={nodes.Wolf3D_Outfit_Footwear.skeleton} />
      <skinnedMesh name="Wolf3D_Outfit_Top" geometry={nodes.Wolf3D_Outfit_Top.geometry} material={materials.Wolf3D_Outfit_Top} skeleton={nodes.Wolf3D_Outfit_Top.skeleton} />
      <skinnedMesh name="Wolf3D_Hair" geometry={nodes.Wolf3D_Hair.geometry} material={materials.Wolf3D_Hair} skeleton={nodes.Wolf3D_Hair.skeleton} />
      <skinnedMesh name="EyeLeft" geometry={nodes.EyeLeft.geometry} material={materials.Wolf3D_Eye} skeleton={nodes.EyeLeft.skeleton} morphTargetDictionary={nodes.EyeLeft.morphTargetDictionary} morphTargetInfluences={nodes.EyeLeft.morphTargetInfluences} />
      <skinnedMesh name="EyeRight" geometry={nodes.EyeRight.geometry} material={materials.Wolf3D_Eye} skeleton={nodes.EyeRight.skeleton} morphTargetDictionary={nodes.EyeRight.morphTargetDictionary} morphTargetInfluences={nodes.EyeRight.morphTargetInfluences} />
      <skinnedMesh name="Wolf3D_Head" geometry={nodes.Wolf3D_Head.geometry} material={materials.Wolf3D_Skin} skeleton={nodes.Wolf3D_Head.skeleton} morphTargetDictionary={nodes.Wolf3D_Head.morphTargetDictionary} morphTargetInfluences={nodes.Wolf3D_Head.morphTargetInfluences} />
      <skinnedMesh name="Wolf3D_Teeth" geometry={nodes.Wolf3D_Teeth.geometry} material={materials.Wolf3D_Teeth} skeleton={nodes.Wolf3D_Teeth.skeleton} morphTargetDictionary={nodes.Wolf3D_Teeth.morphTargetDictionary} morphTargetInfluences={nodes.Wolf3D_Teeth.morphTargetInfluences} />
    </group>
  );
}

const speakText = async (text) => {
  if ("speechSynthesis" in window) {
    const voices = await loadVoices();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 0.9;
    utterance.pitch = 1.0;
    utterance.volume = 1.0;
    utterance.lang = 'en-GB'; // Force UK English
    
    const ukVoice = getUKEnglishFemaleVoice(voices);
    if (ukVoice) {
      utterance.voice = ukVoice;
    }
    
    speechSynthesis.speak(utterance);
    return utterance;
  }
  return null;
};

useGLTF.preload("/models/68d616575327e5b9d7ee6f07.glb");
useGLTF.preload("/models/animations.glb");